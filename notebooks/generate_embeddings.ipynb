{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:10:29.118834758Z",
     "start_time": "2024-01-05T14:10:29.036875982Z"
    }
   },
   "outputs": [],
   "source": [
    "import tomllib\n",
    "import torch\n",
    "from src.utils.utils import dataclass_from_dict\n",
    "from src.model.hyperparameters import Hyperparameters\n",
    "from __future__ import annotations\n",
    "import pathlib\n",
    "import sys\n",
    "from src.model.autoencoder import Autoencoder\n",
    "\n",
    "sys.path.append(pathlib.Path.cwd().parent)\n",
    "\n",
    "def load_model_hyperparameters() -> Hyperparameters:\n",
    "    with (pathlib.Path(\"/home/paolo/git/spotify-playlist-generator/config/model.toml\")).open(\"rb\") as f:\n",
    "        return dataclass_from_dict(Hyperparameters, tomllib.load(f))\n",
    "cfg = load_model_hyperparameters()\n",
    "\n",
    "\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"\")\n",
    "model = Autoencoder.load_from_checkpoint(\"/home/paolo/git/spotify-playlist-generator/logs/mlruns/749985226233759206/0e707c5e421c47098798cc5c91d9532b/artifacts/model/checkpoints/model_checkpoint/model_checkpoint.ckpt\", hyperparam=cfg) #.eval().half().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:10:30.217962589Z",
     "start_time": "2024-01-05T14:10:30.083396410Z"
    }
   },
   "id": "4aa0efcb90ef643c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paolo/git/spotify-playlist-generator/venv/lib/python3.11/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'orm_mode' has been renamed to 'from_attributes'\n",
      "  warnings.warn(message, UserWarning)\n",
      "/home/paolo/git/spotify-playlist-generator/venv/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import v2\n",
    "from src.model.dataset.transforms import MinMaxNorm\n",
    "\n",
    "from src.db.schemas.song_embedding import SongEmbedding\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "\n",
    "transforms: v2.Compose = v2.Compose([\n",
    "    T.MelSpectrogram(\n",
    "        sample_rate=cfg.SAMPLE_RATE,\n",
    "        n_fft=cfg.N_FFT,\n",
    "        win_length=cfg.WIN_LENGTH,\n",
    "        hop_length=cfg.HOP_LENGTH,\n",
    "        n_mels=cfg.N_MELS,\n",
    "        normalized=False,\n",
    "    ),\n",
    "    MinMaxNorm(),\n",
    "    v2.ToDtype(torch.float16, scale=False),\n",
    "])\n",
    "\n",
    "def preprocess(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    tensor = transforms(tensor).to(device).unsqueeze(dim=0)\n",
    "    print(tensor.shape)\n",
    "    return tensor\n",
    "\n",
    "def wrap_prediction_to_song_embedding(tensor: torch.Tensor, song_id: str) -> SongEmbedding:\n",
    "    print(tensor.shape)\n",
    "    return SongEmbedding(id=song_id, embedding=tensor.tolist())\n",
    "\n",
    "def predict_audio(audio: torch.Tensor) -> torch.Tensor:\n",
    "    crop_frames: int = cfg.SAMPLE_RATE * cfg.CROP_SIZE_SECONDS\n",
    "    num_frames: int = audio.shape[1]\n",
    "    last_audio_slice_length: int = num_frames % crop_frames\n",
    "    print(f\"crop_frames: {crop_frames} - num_frames: {num_frames} - last_audio_slice_length: {last_audio_slice_length}\")\n",
    "    \n",
    "    if last_audio_slice_length == 0:\n",
    "        print(f\"length of last audio is equal to the length of a slice\")\n",
    "        pass\n",
    "    elif last_audio_slice_length > crop_frames / 2:\n",
    "        frames_to_add: int = crop_frames - (num_frames % crop_frames)\n",
    "        print(f\"frames_to_add: {frames_to_add}\")\n",
    "        audio = torch.cat([audio, torch.zeros((audio.shape[0], frames_to_add))], dim=1)\n",
    "    else:\n",
    "        frames_to_remove: int = num_frames % crop_frames\n",
    "        print(f\"frames_to_remove: {frames_to_remove}\")\n",
    "        audio = audio[:, :num_frames - frames_to_remove]\n",
    "    \n",
    "    num_slices: int = audio.shape[1] // crop_frames\n",
    "    print(f\"num_frames: {audio.shape[1]} - num_slices: {num_slices}\")\n",
    "    slices: list[torch.Tensor] = torch.chunk(audio, num_slices, dim=1)\n",
    "    return torch.stack([model.encoder(preprocess(slice)) for slice in slices]).squeeze().mean(dim=0)\n",
    "\n",
    "\n",
    "def get_song_embedding(track: dict[str, str]) -> SongEmbedding:\n",
    "    song_id: str = track.get(\"song_id\")\n",
    "    audio_path: str = track.get(\"audio_path\")\n",
    "\n",
    "    audio, _ = torchaudio.load(audio_path)\n",
    "    num_frames: int = audio.shape[1]\n",
    "    crop_frames: int = cfg.CROP_SIZE_SECONDS * cfg.SAMPLE_RATE\n",
    "    if num_frames <= crop_frames:\n",
    "        frames_to_add: int = crop_frames * (num_frames // crop_frames + 1) - num_frames\n",
    "        audio = torch.cat([audio, torch.zeros((audio.shape[0], frames_to_add))], dim=1)\n",
    "        # prediction: torch.Tensor = model.encoder(preprocess(audio))\n",
    "        # print(f\"prediction shape: {prediction.shape}\")\n",
    "        # return wrap_prediction_to_song_embedding(prediction, song_id)\n",
    "\n",
    "    prediction: torch.Tensor = predict_audio(audio)\n",
    "    return wrap_prediction_to_song_embedding(prediction, song_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:05:58.522216031Z",
     "start_time": "2024-01-05T14:05:58.483451711Z"
    }
   },
   "id": "f4e6258a00a2bf03"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "# get_song_embedding({\"song_id\": \"test\", \"audio_path\": \"/home/paolo/git/spotify-playlist-generator/data/raw/songs/1960/4Hhv2vrOTy89HFRcjU3QOx.mp3\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:06:18.522103900Z",
     "start_time": "2024-01-05T14:06:18.517826486Z"
    }
   },
   "id": "58fc3b855e93b4b9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_frames: 1440000 - num_frames: 2159990 - last_audio_slice_length: 719990\n",
      "frames_to_remove: 719990\n",
      "num_frames: 1440000 - num_slices: 1\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "\n",
      "\n",
      "crop_frames: 1440000 - num_frames: 2880000 - last_audio_slice_length: 0\n",
      "length of last audio is equal to the length of a slice\n",
      "num_frames: 2880000 - num_slices: 2\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "\n",
      "\n",
      "crop_frames: 1440000 - num_frames: 8625280 - last_audio_slice_length: 1425280\n",
      "frames_to_add: 14720\n",
      "num_frames: 8640000 - num_slices: 6\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "torch.Size([1, 2, 256, 5626])\n",
      "torch.Size([1, 2, 256, 5626])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([ 7.1430e-04,  4.8685e-04, -4.8351e-04, -2.7504e-03,  2.1877e-03,\n         2.8210e-03,  2.0397e-04, -7.9966e-04,  2.0278e-04,  2.0924e-03,\n         1.9245e-03,  1.9341e-03, -2.3251e-03, -2.1839e-03, -2.5826e-03,\n         3.0231e-04, -1.1587e-03, -1.1702e-03, -8.2350e-04, -6.7186e-04,\n        -2.0084e-03, -3.0136e-03, -3.2616e-04,  1.1148e-03,  3.5801e-03,\n         3.7730e-05,  1.3485e-03, -1.4267e-03, -1.3933e-03, -1.8377e-03,\n         5.7697e-04, -8.5878e-04, -1.8902e-03,  2.2106e-03, -6.4898e-04,\n        -3.5310e-04, -2.3727e-03,  5.2834e-04, -8.5163e-04,  1.4954e-03,\n         5.4502e-04,  8.3876e-04,  9.3269e-04,  5.2452e-04,  7.6199e-04,\n        -7.8678e-04, -7.8583e-04, -3.5167e-04, -2.3174e-04,  3.0875e-04,\n        -4.7660e-04,  1.7416e-04, -1.1187e-03,  3.1877e-04,  1.0748e-03,\n         1.3752e-03, -4.2439e-04,  2.7676e-03,  9.4414e-04,  4.9114e-04,\n         3.8648e-04, -8.1587e-04,  2.9621e-03,  1.5621e-03,  5.8270e-04,\n        -1.7328e-03, -6.2990e-04, -9.9087e-04,  7.5293e-04, -7.6008e-04,\n        -1.0414e-03,  8.7309e-04,  1.3924e-04, -1.2445e-03, -8.4639e-04,\n        -1.4753e-03,  9.2840e-04,  1.4305e-03,  1.2188e-03,  1.0204e-03,\n         5.2154e-05,  2.1496e-03,  5.9700e-04, -4.6754e-04,  2.4090e-03,\n        -6.8843e-05,  2.4109e-03,  1.1997e-03, -4.7851e-04,  3.9160e-05,\n         1.0738e-03, -1.2102e-03,  2.6340e-03,  1.7262e-04, -3.4451e-04,\n         6.0511e-04, -4.1127e-05,  2.2793e-03,  2.3899e-03,  2.4548e-03,\n        -1.4524e-03, -8.3637e-04, -1.5485e-04, -1.3981e-03,  5.0163e-04,\n         2.6703e-03,  8.5735e-04,  3.5763e-05,  1.2846e-03, -2.5177e-03,\n        -1.1873e-03, -2.8210e-03, -6.0499e-05, -6.8378e-04, -8.4972e-04,\n        -9.4557e-04, -2.2449e-03,  1.3530e-04, -9.9945e-04,  9.0551e-04,\n         6.0201e-05,  2.4300e-03,  4.7040e-04, -1.1806e-03,  2.4586e-03,\n        -1.5616e-05, -2.3460e-03, -2.5215e-03], device='cuda:0',\n       dtype=torch.float16, grad_fn=<MeanBackward1>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio, _ = torchaudio.load(\"/home/paolo/git/spotify-playlist-generator/data/raw/songs/1960/4Hhv2vrOTy89HFRcjU3QOx.mp3\")\n",
    "\n",
    "crop_frames = cfg.CROP_SIZE_SECONDS * cfg.SAMPLE_RATE\n",
    "\n",
    "audio_less = audio[:, :2*crop_frames-(crop_frames//2+10)]\n",
    "audio_equal = audio[:, :2*crop_frames]\n",
    "\n",
    "predict_audio(audio_less)\n",
    "print(f\"\\n\")\n",
    "predict_audio(audio_equal)\n",
    "print(f\"\\n\")\n",
    "predict_audio(audio)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:06:20.219879422Z",
     "start_time": "2024-01-05T14:06:19.542079790Z"
    }
   },
   "id": "d7e8ba3819f9dcea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
