{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:46:11.526187150Z",
     "start_time": "2023-12-29T11:46:11.518765837Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm.contrib.concurrent import process_map\n",
    "# import pathlib\n",
    "# from safetensors.torch import save_file\n",
    "# \n",
    "# import torch\n",
    "# import torchaudio\n",
    "# import os\n",
    "# \n",
    "# def get_output_path(path: pathlib.Path) -> str:\n",
    "#     return str(path).replace(\"songs\", \"tensor_songs\").replace(\"mp3\", \"safetensors\")\n",
    "# \n",
    "# def convert_audio_to_tensor(path: pathlib) -> None:\n",
    "#     output_path: pathlib.Path = pathlib.Path(get_output_path(path))\n",
    "#     output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     if output_path.exists():\n",
    "#         return\n",
    "#     \n",
    "#     audio: torch.Tensor\n",
    "#     audio, sample_rate = torchaudio.load(path)\n",
    "#     save_file(\n",
    "#         {\"audio\": audio.contiguous(), \"sample_rate\":torch.tensor(sample_rate, dtype=torch.int32)},\n",
    "#         output_path\n",
    "#     )\n",
    "# \n",
    "# songs_path: list[pathlib.Path] = list((\n",
    "#         pathlib.Path(pathlib.Path.cwd()).parent / \"data\" / \"raw\" / \"songs\"\n",
    "# ).rglob(\"*.mp3\"))\n",
    "# \n",
    "# r = process_map(convert_audio_to_tensor, songs_path, max_workers=os.cpu_count(), chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11G\t/home/paolo/git/spotify-playlist-generator/data/raw/songs\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /home/paolo/git/spotify-playlist-generator/data/raw/songs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:46:11.647899689Z",
     "start_time": "2023-12-29T11:46:11.526758859Z"
    }
   },
   "id": "d593901feca2da80"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172G\t/home/paolo/git/spotify-playlist-generator/data/raw/tensor_songs\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /home/paolo/git/spotify-playlist-generator/data/raw/tensor_songs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:46:11.777396264Z",
     "start_time": "2023-12-29T11:46:11.655457307Z"
    }
   },
   "id": "c97bc0b88a89f0c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert audio to spectrogram image and save it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "832dd5d25afb95c8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 513, 52295]), tensor(0.), tensor(45887.6406))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "SOURCE_FOLDER: str = \"songs\"\n",
    "SOURCE_FORMAT: str = \".mp3\"\n",
    "OUTPUT_FOLDER: str = \"images\"\n",
    "OUTPUT_FORMAT: str = \"png\"\n",
    "\n",
    "class AddChannel(torch.nn.Module):\n",
    "    def __init__(self, channel_type: str = \"mean\"):\n",
    "        assert channel_type in {\"mean\", \"sum\", \"zero\"}\n",
    "        super().__init__()\n",
    "        self.channel_type = channel_type\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.channel_type == \"mean\":\n",
    "            channel: torch.Tensor = x.mean(dim=0).unsqueeze(dim=0)\n",
    "        elif self.channel_type == \"sum\":\n",
    "            channel: torch.Tensor = x.sum(dim=0).unsqueeze(dim=0)\n",
    "        else:\n",
    "            channel: torch.Tensor = torch.zeros((1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        return torch.cat([x, channel], dim=0)\n",
    "\n",
    "\n",
    "def get_output_path(path: pathlib.Path) -> str:\n",
    "    return str(path).replace(SOURCE_FOLDER, OUTPUT_FOLDER).replace(SOURCE_FORMAT, OUTPUT_FORMAT)\n",
    "\n",
    "def convert_audio_to_tensor(path: pathlib) -> None:\n",
    "    output_path: pathlib.Path = pathlib.Path(get_output_path(path))\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if output_path.exists():\n",
    "        return\n",
    "\n",
    "    audio: torch.Tensor\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    \n",
    "    return v2.Compose([\n",
    "        T.Spectrogram(\n",
    "            n_fft=1024,\n",
    "            win_length=1024,\n",
    "            hop_length=256\n",
    "        ),\n",
    "        AddChannel(),\n",
    "        # v2.ToDtype(torch.float32, scale=True)\n",
    "    ])(audio)\n",
    "\n",
    "songs_path: list[pathlib.Path] = list((pathlib.Path(pathlib.Path.cwd()).parent / \"data\" / \"raw\" / SOURCE_FOLDER).rglob(f\"*{SOURCE_FORMAT}\"))\n",
    "\n",
    "audio = convert_audio_to_tensor(songs_path[0])\n",
    "audio.shape, audio.min(), audio.max()\n",
    "# r = process_map(convert_audio_to_tensor, songs_path, max_workers=os.cpu_count(), chunksize=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:55:25.643322701Z",
     "start_time": "2023-12-29T11:55:24.425892065Z"
    }
   },
   "id": "bda43d81e229fd18"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input tensor dtype should be uint8",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_png\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_output_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/spotify-playlist-generator/venv/lib/python3.11/site-packages/torchvision/io/image.py:128\u001B[0m, in \u001B[0;36mwrite_png\u001B[0;34m(input, filename, compression_level)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_tracing():\n\u001B[1;32m    127\u001B[0m     _log_api_usage_once(write_png)\n\u001B[0;32m--> 128\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mencode_png\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompression_level\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    129\u001B[0m write_file(filename, output)\n",
      "File \u001B[0;32m~/git/spotify-playlist-generator/venv/lib/python3.11/site-packages/torchvision/io/image.py:110\u001B[0m, in \u001B[0;36mencode_png\u001B[0;34m(input, compression_level)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_tracing():\n\u001B[1;32m    109\u001B[0m     _log_api_usage_once(encode_png)\n\u001B[0;32m--> 110\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_png\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompression_level\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/git/spotify-playlist-generator/venv/lib/python3.11/site-packages/torch/_ops.py:692\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001B[39;00m\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# is still callable from JIT\u001B[39;00m\n\u001B[1;32m    690\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    691\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 692\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Input tensor dtype should be uint8"
     ]
    }
   ],
   "source": [
    "torchvision.io.write_png(audio, filename=get_output_path(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T11:52:36.545173395Z",
     "start_time": "2023-12-29T11:52:36.526057707Z"
    }
   },
   "id": "4056ae9c609e2cf5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
